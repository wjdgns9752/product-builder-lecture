// Firebase Integration (Global UMD)
// Imports removed. Using 'firebase' global object.

const firebaseConfig = {
  apiKey: "AIzaSyB80YVLtFSBs2l3TiazSRj0xsgOBeUZG4I",
  authDomain: "noise-monitoring-5764d.firebaseapp.com",
  projectId: "noise-monitoring-5764d",
  storageBucket: "noise-monitoring-5764d.firebasestorage.app",
  messagingSenderId: "250708015230",
  appId: "1:250708015230:web:676e299df9ef6ca00d002f",
  measurementId: "G-1BCMY7SVDQ"
};

// Initialize Firebase
const app = firebase.initializeApp(firebaseConfig);
const db = firebase.firestore();
const auth = firebase.auth();

// DOM Elements
const initBtn = document.getElementById('init-btn');
const recordBtn = document.getElementById('record-btn');
const meterBar = document.getElementById('meter-bar');
const bgMarker = document.getElementById('bg-marker');
const currentVolSpan = document.getElementById('current-vol');
const bgVolSpan = document.getElementById('bg-vol');
const statusText = document.getElementById('status-text');
const durationBar = document.getElementById('duration-bar'); 
const canvas = document.getElementById('visualizer');
const canvasCtx = canvas.getContext('2d');
const thresholdSlider = document.getElementById('threshold');
const thresholdVal = document.getElementById('threshold-val');
const audioAlarmCheckbox = document.getElementById('audio-alarm');
const themeToggleBtn = document.getElementById('theme-toggle');
const body = document.body;

// Auth / User Elements
const authModal = document.getElementById('auth-modal');
const authNicknameInput = document.getElementById('auth-nickname');
const btnStart = document.getElementById('btn-start');
const userNicknameDisplay = document.getElementById('user-nickname-display');
const userInfoModal = document.getElementById('user-info-modal'); // Onboarding

let currentUserId = localStorage.getItem('user_uid'); // Persist ID
let currentUserNickname = localStorage.getItem('user_nickname');
let userProfile = null;

// --- Auth / Nickname Logic ---
function checkAuth() {
    if (!currentUserId || !currentUserNickname) {
        // No User -> Show Nickname Modal
        authModal.classList.remove('hidden');
        userInfoModal.classList.add('hidden');
    } else {
        // User Exists
        userNicknameDisplay.textContent = currentUserNickname;
        authModal.classList.add('hidden');
        checkUserProfile(currentUserId);
    }
}

// Generate a simple UUID if not exists
function generateUUID() {
    return 'user_' + Math.random().toString(36).substr(2, 9) + Date.now().toString(36);
}

btnStart.addEventListener('click', (e) => {
    e.preventDefault();
    const nickname = authNicknameInput.value.trim();
    
    if (nickname) {
        // Create new session
        currentUserId = generateUUID();
        currentUserNickname = nickname;
        
        localStorage.setItem('user_uid', currentUserId);
        localStorage.setItem('user_nickname', currentUserNickname);
        
        userNicknameDisplay.textContent = currentUserNickname;
        authModal.classList.add('hidden');
        
        // New user needs profile setup
        showOnboarding(false);
    } else {
        alert("ÎãâÎÑ§ÏûÑÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.");
    }
});


async function checkUserProfile(uid) {
    try {
        const docRef = db.collection("users").doc(uid);
        const docSnap = await docRef.get();

        if (docSnap.exists) {
            userProfile = docSnap.data();
            // Periodic Check (7 days)
            const lastUpdate = userProfile.updatedAt || 0;
            const now = Date.now();
            const CHECK_INTERVAL_MS = 7 * 24 * 60 * 60 * 1000;
            
            if ((now - lastUpdate) > CHECK_INTERVAL_MS) {
                showOnboarding(true); // Show Re-check
            }
        } else {
            // No Profile in DB -> Show Onboarding
            showOnboarding(false);
        }
    } catch (e) {
        console.error("Profile check failed:", e);
    }
}

function showOnboarding(isUpdate) {
    userInfoModal.classList.remove('hidden');
    userInfoModal.style.display = 'flex';
    if (isUpdate) {
        userInfoModal.querySelector('h2').textContent = "üìÖ Ï†ïÍ∏∞ ÌôòÍ≤Ω Ï†êÍ≤Ä";
        userInfoModal.querySelector('.desc').innerHTML = "7ÏùºÏù¥ ÏßÄÎÇ¨ÏäµÎãàÎã§.<br>ÌôòÍ≤Ω Ï†ïÎ≥¥Î•º ÏóÖÎç∞Ïù¥Ìä∏Ìï¥Ï£ºÏÑ∏Ïöî.";
    }
}

async function saveUserInfo() {
    try {
        console.log("saveUserInfo called");
        
        // Hide modal immediately
        if (userInfoModal) {
            userInfoModal.classList.add('hidden');
            userInfoModal.style.display = 'none';
        }

        const housingType = document.getElementById('housing-type').value;
        const floorLevel = document.getElementById('floor-level').value;
        const envType = document.getElementById('env-type').value;

        const profile = {
            housingType,
            floorLevel,
            envType,
            updatedAt: Date.now()
        };

        // Save to localStorage
        localStorage.setItem('user_profile', JSON.stringify(profile));
        
        // Save to Firestore (Fire and forget, safe catch)
        if (currentUserId && typeof db !== 'undefined') {
            db.collection("users").doc(currentUserId).set(profile, { merge: true })
                .then(() => console.log("User profile saved to Firestore."))
                .catch((error) => console.error("Error saving user profile: ", error));
        }

        // Auto Start
        console.log("Attempting auto-start audio...");
        const success = await startAudio();
        if (!success) {
            console.warn("Auto-start failed.");
            if (initBtn) initBtn.style.display = 'block';
            // Alert strictly if it didn't work (and no permission modal showed)
            // But startAudio handles permission modal.
        }
    } catch (e) {
        console.error("saveUserInfo critical error:", e);
        alert("ÏÑ§Ï†ïÏùÑ Ï†ÄÏû•ÌïòÎäî Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: " + e.message);
        // Ensure modal is closed so user isn't stuck
        if (userInfoModal) userInfoModal.classList.add('hidden');
        if (initBtn) initBtn.style.display = 'block';
    }
}

// Init Check
checkAuth();

// Calibration Elements
const realDbInput = document.getElementById('real-db-input');
const autoCalibBtn = document.getElementById('auto-calib-btn');
const currentRawDbSpan = document.getElementById('current-raw-db');
const saveCalibBtn = document.getElementById('save-calib');
const cancelCalibBtn = document.getElementById('cancel-calib');
const calibBtn = document.getElementById('calibration-btn');
const calibModal = document.getElementById('calibration-modal');
const playNoiseBtn = document.getElementById('play-noise-btn');

// Evaluation Modal Elements
const modal = document.getElementById('evaluation-modal');
const rateBtns = document.querySelectorAll('.rate-btn');
const submitEvalBtn = document.getElementById('submit-eval');
const selectedValSpan = document.getElementById('selected-val');
const audioPreviewContainer = document.getElementById('audio-preview-container');
const noisePlayer = document.getElementById('noise-player');
const downloadLink = document.getElementById('download-recording');

// Classifier Elements
const classCards = {
    floor: document.getElementById('type-floor'),
    home: document.getElementById('type-home'),
    road: document.getElementById('type-road'),
    train: document.getElementById('type-train'),
    air: document.getElementById('type-air')
};

// ...

// --- Independent AI Module (YAMNet) ---
let aiProcessor = null;
let aiModel = null;

// Helper to load scripts dynamically
function loadScript(url) {
    return new Promise((resolve, reject) => {
        const script = document.createElement('script');
        script.src = url;
        script.onload = resolve;
        script.onerror = reject;
        document.head.appendChild(script);
    });
}

async function setupAI(stream) {
    const statusLabel = document.getElementById('ai-loader');
    const meterFill = document.getElementById('ai-meter-fill');
    const resultText = document.getElementById('ai-result-text');
    
    try {
        // 1. Load Scripts Dynamically if not present
        if (typeof tf === 'undefined') {
            statusLabel.textContent = "‚è≥ TFJS Îã§Ïö¥Î°úÎìú Ï§ë...";
            await loadScript('https://unpkg.com/@tensorflow/tfjs@3.13.0/dist/tf.min.js');
        }
        
        if (typeof yamnet === 'undefined') {
            statusLabel.textContent = "‚è≥ YAMNet Îã§Ïö¥Î°úÎìú Ï§ë...";
            await loadScript('https://unpkg.com/@tensorflow-models/yamnet@0.0.1/dist/yamnet.min.js');
        }

        // 2. Load Model
        if (!aiModel) {
            statusLabel.textContent = "‚è≥ AI Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ï§ë...";
            aiModel = await yamnet.load();
            statusLabel.textContent = "‚úÖ AI Ï§ÄÎπÑ ÏôÑÎ£å (Î∂ÑÏÑù Ï§ë)";
        }
        
        // 3. Hook into existing AudioContext (Best for compatibility)
        if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        const micInput = audioContext.createMediaStreamSource(stream);
        
        // Use ScriptProcessor (bufferSize 4096) for resampling
        // This runs on the main thread but is widely supported
        if (aiProcessor) aiProcessor.disconnect();
        aiProcessor = audioContext.createScriptProcessor(4096, 1, 1);
        
        micInput.connect(aiProcessor);
        aiProcessor.connect(audioContext.destination); // Needed for processing to happen
        
        // Circular Buffer for Resampling
        const targetRate = 16000;
        let buffer16k = [];
        
        aiProcessor.onaudioprocess = async (e) => {
            const inputData = e.inputBuffer.getChannelData(0);
            const originalRate = e.inputBuffer.sampleRate;
            
            // Visual feedback (RMS Meter)
            let sum = 0;
            for(let i=0; i<inputData.length; i+=10) sum += inputData[i]*inputData[i];
            const rms = Math.sqrt(sum / (inputData.length/10));
            if(meterFill) meterFill.style.width = `${Math.min(100, rms * 800)}%`;
            
            // 3. Resample & Accumulate
            // Simple Decimation (Skip samples)
            const step = originalRate / targetRate;
            for (let i = 0; i < inputData.length; i += step) {
                buffer16k.push(inputData[Math.floor(i)]);
            }
            
            // 4. Predict when buffer is full (16000 samples = 1 sec)
            if (buffer16k.length >= 16000) {
                const chunk = new Float32Array(buffer16k.slice(0, 16000));
                
                // Sliding window: Remove old data (keep 50% overlap for smoothness)
                // Remove first 8000 samples
                buffer16k = buffer16k.slice(8000); 
                
                // Only predict if audible sound exists
                if (rms > 0.01) { 
                    const results = await aiModel.predict(chunk);
                    const top = findTopClass(results[0]);
                    updateAIUI(top, resultText);
                    results[0].dispose(); // Clean Tensor
                } else {
                    updateAIUI({ label: 'Silence', score: 0 }, resultText);
                }
            }
        };
        
    } catch (e) {
        console.error("AI Setup Error:", e);
        statusLabel.textContent = "‚ö†Ô∏è AI Ïò§Î•ò: " + e.message;
    }
}

function findTopClass(scores) {
    const values = scores.dataSync();
    const classMap = aiModel.classMap;
    let max = -1;
    let index = -1;
    for(let i=0; i<values.length; i++) {
        if(values[i] > max) { max = values[i]; index = i; }
    }
    return { label: classMap[index], score: max };
}

function updateAIUI(prediction, resultEl) {
    const cards = {
        home: document.getElementById('card-home'),
        floor: document.getElementById('card-floor'),
        road: document.getElementById('card-road'),
        train: document.getElementById('card-train'),
        air: document.getElementById('card-air'),
        none: document.getElementById('card-none')
    };
    
    // Reset
    Object.values(cards).forEach(c => c && c.classList.remove('active'));
    
    const label = prediction.label.toLowerCase();
    const score = prediction.score;
    
    if (resultEl) resultEl.textContent = `${prediction.label} (${(score*100).toFixed(0)}%)`;

    // Logic
    if (label.includes('silence') || score < 0.25) {
        if(cards.none) cards.none.classList.add('active');
        return;
    }

    // 1. Home / Internal
    if (label.includes('speech') || label.includes('music') || label.includes('domestic') || 
        label.includes('cooking') || label.includes('water') || label.includes('vacuum') ||
        label.includes('cleaning') || label.includes('wash') || label.includes('conversation') ||
        label.includes('typing') || label.includes('mouse') || label.includes('click')) {
        if(cards.home) cards.home.classList.add('active');
        return;
    }

    // 2. Floor / Impact
    if (label.includes('thump') || label.includes('knock') || label.includes('footsteps') || 
        label.includes('impact') || label.includes('door') || label.includes('wood') || label.includes('tap')) {
        if(cards.floor) cards.floor.classList.add('active');
        return;
    }

    // 3. Road
    if (label.includes('traffic') || label.includes('vehicle') || label.includes('car') || 
        label.includes('bus') || label.includes('truck') || label.includes('motor') || 
        label.includes('engine') || label.includes('street') || label.includes('siren')) {
        if(cards.road) cards.road.classList.add('active');
        return;
    }

    // 4. Train
    if (label.includes('train') || label.includes('rail') || label.includes('subway') || label.includes('tram')) {
        if(cards.train) cards.train.classList.add('active');
        return;
    }

    // 5. Air
    if (label.includes('aircraft') || label.includes('airplane') || label.includes('jet') || label.includes('helicopter')) {
        if(cards.air) cards.air.classList.add('active');
        return;
    }
    
    // Fallback -> Home
    if(cards.home) cards.home.classList.add('active');
}

// ... rest of the code ...

// Survey Elements
const chipGroups = {
    activity: document.querySelectorAll('.chip[data-type="activity"]'),
    source: document.querySelectorAll('.chip[data-type="source"]')
};
let surveyData = {
    activity: null,
    source: null
};

// State Variables
let audioContext;
let analyser;
let microphone;
let globalStream = null; // Store stream for MediaRecorder
let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;
let recordedBlob = null;
let currentAudioUrl = null;

let isMonitoring = false;
let isPausedForEval = false; 
let isCalibrating = false; // Prevents alarm during calibration
let selectedRating = null;
let currentVolumeValue = 0; 

// Calibration State
let dbOffset = parseFloat(localStorage.getItem('dbOffset')) || 0; 
let noiseNode = null; 
let isPlayingNoise = false;

// Duration Logic
let noiseStartTime = 0;
const TRIGGER_DURATION_MS = 2000; 
let lastEvalTime = 0;
const GRACE_PERIOD_MS = 3000; 
let audioInitTime = 0; // Warm-up timer

// Background Noise Tracking (in dB)
let backgroundLevel = 40; // Default est. dB
const adaptationRate = 0.005; 
const decayRate = 0.05;      

// --- Advanced Analysis Variables ---
const dbBuffer = []; // Stores recent dB values for stats (L90, Leq)
const BUFFER_SIZE = 300; // Approx 30 seconds (assuming 100ms push)
let lastAnalysisTime = 0;

// Visualizer State
let tempCanvas = document.createElement('canvas');
let tempCtx = tempCanvas.getContext('2d');
tempCanvas.width = canvas.width;
tempCanvas.height = canvas.height;

// Permission Modal
const permissionModal = document.getElementById('permission-modal');

// --- Theme Logic ---
const currentTheme = localStorage.getItem('theme');
if (currentTheme === 'dark') {
  body.classList.add('dark-mode');
}
themeToggleBtn.addEventListener('click', () => {
  body.classList.toggle('dark-mode');
  const theme = body.classList.contains('dark-mode') ? 'dark' : 'light';
  localStorage.setItem('theme', theme);
});

// --- Settings Logic ---
thresholdSlider.addEventListener('input', (e) => {
  thresholdVal.textContent = e.target.value;
});

// --- Audio Functions ---
async function startAudio() {
  try {
    if (audioContext && audioContext.state === 'closed') {
        audioContext = null;
    }

    if (!audioContext) {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
    }
    if (audioContext.state === 'suspended') {
      await audioContext.resume();
    }

    // Only create stream if not already created
    if (!microphone) {
        const constraints = {
            audio: {
                echoCancellation: false,
                noiseSuppression: false,
                autoGainControl: false
            },
            video: false
        };

        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        globalStream = stream; // Store for MediaRecorder
        
        microphone = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048; 
        analyser.smoothingTimeConstant = 0.6; 
        
        microphone.connect(analyser);
        
        // Start AI Module independently
        setupAI(stream);
    }

    initBtn.style.display = 'none';
    recordBtn.classList.remove('hidden'); // Show record button
    
    if (!isMonitoring) {
        isMonitoring = true;
        audioInitTime = Date.now(); // Set warm-up start time
        statusText.textContent = "ÏÉÅÌÉú: ÏïàÏ†ïÌôî Ï§ë..."; // Update status
        analyze();
        drawSpectrogram();
    }
    
    return true; 
  } catch (err) {
    console.error('Error accessing microphone:', err);
    if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
        if(permissionModal) {
            permissionModal.classList.remove('hidden');
            permissionModal.style.display = 'flex';
        } else {
            alert("ÎßàÏù¥ÌÅ¨ Í∂åÌïúÏù¥ Ï∞®Îã®ÎêòÏóàÏäµÎãàÎã§. ÏÑ§Ï†ïÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.");
        }
        return false;
    }
    // Simple fallback
    try {
        if (!microphone) {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            globalStream = stream;
            microphone = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048; 
            analyser.smoothingTimeConstant = 0.6; 
            microphone.connect(analyser);
        }
        initBtn.style.display = 'none';
        
        if (!isMonitoring) {
            isMonitoring = true;
            analyze();
            drawSpectrogram();
        }
        return true;
    } catch (fallbackErr) {
        return false;
    }
  }
}

// --- Recorder Logic ---
function startRecording() {
    if (!globalStream || isRecording) return;
    try {
        mediaRecorder = new MediaRecorder(globalStream);
        audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };

        mediaRecorder.start();
        isRecording = true;
        // console.log("Recording started...");
    } catch (e) {
        console.error("MediaRecorder start failed", e);
    }
}

function stopRecording(save = false) {
    if (!mediaRecorder || !isRecording) return;
    
    // We need to wait for the final 'dataavailable' event
    // So we wrap the stop logic in a promise or handle it in onstop
    
    return new Promise((resolve) => {
        mediaRecorder.onstop = () => {
            isRecording = false;
            // console.log("Recording stopped. Saved:", save);
            if (save && audioChunks.length > 0) {
                recordedBlob = new Blob(audioChunks, { type: 'audio/webm' });
                resolve(recordedBlob);
            } else {
                recordedBlob = null;
                resolve(null);
            }
        };
        mediaRecorder.stop();
    });
}

function cancelRecording() {
    if (isRecording && mediaRecorder) {
        // Stop without saving intent (though stop() always fires dataavailable, logic above handles save flag)
        mediaRecorder.stop(); 
        isRecording = false;
        audioChunks = []; // Clear immediately
        recordedBlob = null;
        // console.log("Recording cancelled.");
    }
}

// --- Device Detection Helper ---
function getDeviceReferenceSPL() {
    const ua = navigator.userAgent;
    let model = "Unknown Device";
    let refSPL = 75; 

    if (/iPhone|iPad|iPod/.test(ua)) {
        model = "Apple iPhone/iPad";
        refSPL = 79; 
    } else {
        const match = ua.match(/;\s([^;]+)\sBuild/);
        if (match) {
            model = match[1].trim();
            if (model.includes("SM-S") || model.includes("SM-G") || model.includes("SM-N") || model.includes("SM-F")) {
                refSPL = 78;
            } else if (model.includes("SM-A") || model.includes("SM-M")) {
                refSPL = 74;
            } else if (model.toLowerCase().includes("pixel")) {
                refSPL = 77;
            }
        }
    }
    return { model, refSPL };
}

// --- Auto Calibration Logic ---
if (autoCalibBtn) {
    autoCalibBtn.addEventListener('click', async () => {
        // Reset Eval UI
        isPausedForEval = false;
        if (modal) modal.classList.add('hidden');

        // Set Flag
        isCalibrating = true;
        statusText.textContent = "ÏÉÅÌÉú: ÎßàÏù¥ÌÅ¨ Ï†ïÎ∞Ä Î≥¥Ï†ï Ï§ë... (3Îã®Í≥Ñ)";

        if (!audioContext || audioContext.state === 'suspended') {
            const success = await startAudio();
            if (!success) {
                isCalibrating = false;
                return;
            }
        }

        const { model, refSPL } = getDeviceReferenceSPL();
        const referenceSPL = refSPL; 

        autoCalibBtn.disabled = true;
        
        try {
            const iterations = 3;
            let measuredOffsets = [];

            for (let i = 1; i <= iterations; i++) {
                autoCalibBtn.textContent = `‚è≥ Ï∏°Ï†ï Ï§ë... (${i}/${iterations})`;
                statusText.textContent = `ÏÉÅÌÉú: Ï∏°Ï†ï ${i}/${iterations} ÏßÑÌñâ Ï§ë...`;
                
                // 1. Play Noise
                if (!isPlayingNoise) playPinkNoise();
                
                // Wait for noise to stabilize
                await new Promise(r => setTimeout(r, 1000));

                // 2. Measure
                let sumDb = 0;
                let samples = 0;
                const measurePromise = new Promise(resolve => {
                    const interval = setInterval(() => {
                        const rawDb = parseFloat(currentRawDbSpan.textContent);
                        if (!isNaN(rawDb) && rawDb > -100) {
                            sumDb += rawDb;
                            samples++;
                        }
                    }, 100);

                    // Measure for 2 seconds
                    setTimeout(() => {
                        clearInterval(interval);
                        resolve(samples > 0 ? sumDb / samples : null);
                    }, 2000);
                });

                const avgRawDb = await measurePromise;
                
                // 3. Stop Noise (briefly)
                stopPinkNoise();
                await new Promise(r => setTimeout(r, 500)); // Quiet gap

                if (avgRawDb !== null) {
                    const offset = referenceSPL - avgRawDb;
                    measuredOffsets.push(offset);
                    console.log(`Calibration Step ${i}: Raw=${avgRawDb.toFixed(2)}, Offset=${offset.toFixed(2)}`);
                }
            }

            // Final Calculation
            if (measuredOffsets.length > 0) {
                // 1. Calculate Average
                const totalOffset = measuredOffsets.reduce((a, b) => a + b, 0);
                const finalOffset = totalOffset / measuredOffsets.length;

                // 2. Calculate Standard Deviation (Stability Check)
                const variance = measuredOffsets.reduce((sum, val) => sum + Math.pow(val - finalOffset, 2), 0) / measuredOffsets.length;
                const stdDev = Math.sqrt(variance);

                // 3. Determine Precision Grade
                let grade = '';
                let gradeDesc = '';
                
                if (stdDev < 1.0) {
                    grade = 'S (ÏµúÏö∞Ïàò)';
                    gradeDesc = 'ÏïÑÏ£º ÏôÑÎ≤ΩÌï¥Ïöî! Ï†ÑÎ¨∏ Ïû•ÎπÑ ÏàòÏ§ÄÏùò ÏïàÏ†ïÏÑ±ÏûÖÎãàÎã§.';
                } else if (stdDev < 2.5) {
                    grade = 'A (Ïö∞Ïàò)';
                    gradeDesc = 'ÏïàÏ†ïÏ†ÅÏûÖÎãàÎã§. ÏùºÏÉÅ Î™®ÎãàÌÑ∞ÎßÅÏóê Ï∂©Î∂ÑÌï¥Ïöî.';
                } else if (stdDev < 5.0) {
                    grade = 'B (Î≥¥ÌÜµ)';
                    gradeDesc = 'ÏïΩÍ∞ÑÏùò Ìé∏Ï∞®Í∞Ä ÏûàÏñ¥Ïöî. Ï£ºÎ≥ÄÏù¥ ÏãúÎÅÑÎü¨Ïõ†ÎÇòÏöî?';
                } else {
                    grade = 'F (Î∂àÏïàÏ†ï)';
                    gradeDesc = 'Ï∏°Ï†ïÍ∞íÏù¥ ÌäëÎãàÎã§. Îçî Ï°∞Ïö©Ìïú Í≥≥ÏóêÏÑú Îã§Ïãú Ìï¥Î≥¥ÏÑ∏Ïöî.';
                }

                dbOffset = finalOffset;
                localStorage.setItem('dbOffset', dbOffset);
                
                alert(`[Ï†ïÎ∞Ä Î≥¥Ï†ï ÏôÑÎ£å]\n\nüèÜ ÎßàÏù¥ÌÅ¨/ÌôòÍ≤Ω Îì±Í∏â: ${grade}\nüìä ÏïàÏ†ïÏÑ±(Ìé∏Ï∞®): ¬±${stdDev.toFixed(2)}dB\n‚úÖ ÏµúÏ¢Ö Î≥¥Ï†ïÍ∞í: ${dbOffset.toFixed(1)} dB\n\nüí° ${gradeDesc}`);
                calibModal.classList.add('hidden');
            } else {
                alert("Ï∏°Ï†ï Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî.");
            }

        } catch (e) {
            console.error(e);
            alert("Î≥¥Ï†ï Ï§ë Ïò§Î•ò Î∞úÏÉù");
        } finally {
            // Reset UI
            autoCalibBtn.disabled = false;
            autoCalibBtn.textContent = "üöÄ Ï†ïÎ∞Ä ÏûêÎèô Î≥¥Ï†ï ÏãúÏûë (3Ìöå)";
            isCalibrating = false;
            statusText.textContent = "ÏÉÅÌÉú: Í∞êÏßÄ Ï§ë...";
            stopPinkNoise();
        }
    });
}

// --- Admin Mode Logic ---
const adminBtn = document.getElementById('admin-mode-btn');
const adminModal = document.getElementById('admin-modal');
const adminAppDbSpan = document.getElementById('admin-app-db');
const adminRefInput = document.getElementById('admin-ref-db');
const adminLogBtn = document.getElementById('admin-log-btn');
const adminLogTable = document.getElementById('admin-log-table');
const adminMaeSpan = document.getElementById('admin-mae');

let adminLogs = [];
let isAdminModeOpen = false;

if (adminBtn) {
    adminBtn.addEventListener('click', (e) => {
        e.preventDefault();
        adminModal.classList.remove('hidden');
        isAdminModeOpen = true;
        updateAdminDisplay();
    });
}

function updateAdminDisplay() {
    if (!isAdminModeOpen || adminModal.classList.contains('hidden')) {
        isAdminModeOpen = false;
        return;
    }
    requestAnimationFrame(updateAdminDisplay);
    // Update current App dB in Admin Modal
    adminAppDbSpan.textContent = currentVolumeValue.toFixed(1);
}

if (adminLogBtn) {
    adminLogBtn.addEventListener('click', () => {
        const refDb = parseFloat(adminRefInput.value);
        const appDb = parseFloat(adminAppDbSpan.textContent);

        if (isNaN(refDb)) {
            alert("ÏÜåÏùåÍ≥Ñ Ï∏°Ï†ïÍ∞í(Ïà´Ïûê)ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.");
            return;
        }

        const diff = appDb - refDb;
        const logItem = {
            id: adminLogs.length + 1,
            app: appDb.toFixed(1),
            ref: refDb.toFixed(1),
            diff: diff.toFixed(1)
        };
        adminLogs.push(logItem);
        renderAdminLogs();
        adminRefInput.value = ''; // Clear input
        adminRefInput.focus();
    });
}

function renderAdminLogs() {
    adminLogTable.innerHTML = adminLogs.map(log => `
        <tr style="border-bottom: 1px solid #eee;">
            <td style="padding:8px;">${log.id}</td>
            <td style="padding:8px;">${log.app}</td>
            <td style="padding:8px;">${log.ref}</td>
            <td style="padding:8px; color:${Math.abs(log.diff) > 3 ? 'red' : 'green'}">${log.diff > 0 ? '+' : ''}${log.diff}</td>
        </tr>
    `).join('');

    // Calculate MAE (Mean Absolute Error)
    const totalError = adminLogs.reduce((sum, log) => sum + Math.abs(parseFloat(log.diff)), 0);
    const mae = totalError / adminLogs.length;
    adminMaeSpan.textContent = mae.toFixed(2);
}

// --- Audio Init Button ---
initBtn.addEventListener('click', async () => {
  await startAudio();
});

// --- Analysis Loop ---
function analyze() {
  requestAnimationFrame(analyze);
  if (!isMonitoring || isPausedForEval) return;

  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);
  analyser.getByteFrequencyData(dataArray);

  let sum = 0;
  for(let i = 0; i < bufferLength; i++) {
    const x = dataArray[i] / 255; 
    sum += x * x;
  }
  const rms = Math.sqrt(sum / bufferLength);
  let rawDb = 20 * Math.log10(rms + 0.00001); 
  let calibratedDb = rawDb + dbOffset;
  if (calibratedDb < 0) calibratedDb = 0;
  currentVolumeValue = calibratedDb;
  
  if (!calibModal.classList.contains('hidden')) {
      currentRawDbSpan.textContent = rawDb.toFixed(1);
  }

  // Classifier
  if (calibratedDb > 40 && !isCalibrating) { 
      let lowEnergy = 0, midLowEnergy = 0, midHighEnergy = 0, voiceEnergy = 0;
      
      // Frequency Bands (Approximate for 44.1kHz / 2048 FFT)
      // Bin size ~= 21.5 Hz
      for(let i=0; i<8; i++) lowEnergy += dataArray[i]; // ~0-170Hz (Floor/Impact)
      for(let i=14; i<140; i++) voiceEnergy += dataArray[i]; // ~300-3000Hz (Human Voice Range)
      for(let i=10; i<42; i++) midLowEnergy += dataArray[i]; // ~200-900Hz (Road/Home)
      for(let i=42; i<170; i++) midHighEnergy += dataArray[i]; // ~900-3600Hz (Air/Hiss)
      
      lowEnergy /= 8; 
      voiceEnergy /= 126;
      midLowEnergy /= 32; 
      midHighEnergy /= 128;

      const maxEnergy = Math.max(lowEnergy, voiceEnergy, midLowEnergy, midHighEnergy);
      
      Object.values(classCards).forEach(c => { if(c) c.classList.remove('active'); });
      
      if (maxEnergy === lowEnergy && lowEnergy > 50) {
          if (classCards.floor) classCards.floor.classList.add('active'); 
      }
      else if (maxEnergy === voiceEnergy && voiceEnergy > midLowEnergy * 1.2) {
          // Voice needs to be distinct from general mid-noise
          if (classCards.voice) classCards.voice.classList.add('active');
      }
      else if (maxEnergy === midLowEnergy) {
           if (midLowEnergy > 150) { if(classCards.air) classCards.air.classList.add('active'); }
           else { if(classCards.road) classCards.road.classList.add('active'); }
      } 
      else { if(classCards.home) classCards.home.classList.add('active'); }
  } else {
      Object.values(classCards).forEach(c => { if(c) c.classList.remove('active'); });
  }

  // Background
  if (calibratedDb < backgroundLevel) {
      backgroundLevel = Math.max(10, backgroundLevel * (1 - decayRate) + calibratedDb * decayRate);
  } else backgroundLevel = backgroundLevel * (1 - adaptationRate) + calibratedDb * adaptationRate;
  
  // Push to Buffer for Advanced Analysis
  dbBuffer.push(calibratedDb);
  if (dbBuffer.length > BUFFER_SIZE) dbBuffer.shift();

  // Run Advanced Analysis every 500ms
  const now = Date.now();
  if (now - lastAnalysisTime > 500) {
      updateAnalysis();
      lastAnalysisTime = now;
  }

  updateUI(calibratedDb, backgroundLevel);
  checkThreshold(calibratedDb, backgroundLevel);
}

// --- Advanced Analysis Function ---
function updateAnalysis() {
    if (dbBuffer.length < 50) return; // Need at least 5 seconds of data

    // 1. Calculate Statistics (Sorted for Percentiles)
    const sortedDb = [...dbBuffer].sort((a, b) => a - b);
    const L90 = sortedDb[Math.floor(sortedDb.length * 0.1)]; // Background (Quiet 10%)
    const L10 = sortedDb[Math.floor(sortedDb.length * 0.9)]; // Peak (Noisy 10%)
    
    // Calculate Leq (Logarithmic Average)
    let sumEnergy = 0;
    for (let db of dbBuffer) {
        sumEnergy += Math.pow(10, db / 10);
    }
    const Leq = 10 * Math.log10(sumEnergy / dbBuffer.length);

    // 2. Metrics for Harmonica & Event Index
    const eventImpact = Math.max(0, Leq - L90); // Component of noise due to events
    const fluctuation = L10 - L90; // Intermittency Proxy
    const intrusivenessRatio = (eventImpact / Math.max(1, Leq)) * 100; // % of total noise that is 'event'

    // 3. Update UI Elements
    const valL90 = document.getElementById('val-l90');
    if (valL90) valL90.textContent = L90.toFixed(1);
    
    const valEvent = document.getElementById('val-event');
    if (valEvent) valEvent.textContent = eventImpact.toFixed(1);
    
    const valIr = document.getElementById('val-ir');
    if (valIr) valIr.textContent = fluctuation.toFixed(1); // Using Fluctuation as simplified IR

    // Dynamic Descriptions (Academic/Scientific Context)
    const descEvent = document.getElementById('desc-event');
    const descIr = document.getElementById('desc-ir');
    
    if (descEvent) {
        if (eventImpact < 3) descEvent.textContent = "Low Salience (Î∞∞Í≤Ω ÏÜåÏùå Ïö∞ÏÑ∏)";
        else if (eventImpact < 8) descEvent.textContent = "Moderate Salience (Ïù¥Î≤§Ìä∏ Í∞êÏßÄÎê®)";
        else descEvent.textContent = "High Acoustic Salience (Í∞ïÌïú ÎèåÎ∞úÏÑ±, Harmonica Index‚Üë)";
    }
    
    if (descIr) {
        if (fluctuation < 10) descIr.textContent = "Constant (ÏãúÍ∞ÑÏ†Å Íµ¨Ï°∞ ÏïàÏ†ï)";
        else if (fluctuation < 30) descIr.textContent = "Fluctuating (ÏùºÎ∞òÏ†Å Î≥ÄÎèô)";
        else descIr.textContent = "High Intermittency (ÎÜíÏùÄ Í∞ÑÌóêÏÑ±, DYNAMAP Í∏∞Ï§Ä)";
    }

    // Harmonica 'Pencil' Visualization
    const pencilWrapper = document.querySelector('.pencil-wrapper');
    const pencilBody = document.getElementById('pencil-body');
    const pencilTip = document.getElementById('pencil-tip');
    const labelBody = document.getElementById('label-body');
    const labelTip = document.getElementById('label-tip');

    if (pencilWrapper && pencilBody && pencilTip) {
        // Map dB to % (Scale: 0dB to 120dB)
        const maxScale = 120;
        const totalLeqPercent = Math.min(100, Math.max(0, (Leq / maxScale) * 100));
        
        // Width of the entire pencil (Total Leq)
        pencilWrapper.style.width = `${totalLeqPercent}%`;
        
        // Inside the pencil: split between Body (L90) and Tip (Event)
        // Ratio of Background to Total
        const totalVal = Math.max(0.1, Leq); // Avoid divide by zero
        const bodyPercent = (L90 / totalVal) * 100;
        const tipPercent = 100 - bodyPercent;

        pencilBody.style.width = `${bodyPercent}%`;
        pencilTip.style.width = `${tipPercent}%`;
        
        // Update Labels inside pencil
        if (labelBody) labelBody.textContent = L90.toFixed(0);
        if (labelTip) labelTip.textContent = eventImpact > 1 ? `+${eventImpact.toFixed(0)}` : '';
    }
    
    // 4. Generate Comment (Contextual Analysis)
    const badge = document.getElementById('noise-badge');
    const comment = document.getElementById('analysis-comment');
    
    if (badge && comment) {
        // Logic based on HARMONICA/DYNAMAP concepts
        if (fluctuation < 5) {
            badge.textContent = "Steady (ÏßÄÏÜçÏùå)";
            badge.className = "badge steady";
            comment.textContent = "Î≥ÄÎèôÏù¥ Ï†ÅÏùÄ ÏßÄÏÜçÏ†ÅÏù∏ ÏÜåÏùåÏûÖÎãàÎã§. (Ïòà: ÎÉâÏû•Í≥†, Î©ÄÎ¶¨ÏÑú Îì§Î¶¨Îäî ÎèÑÎ°ú ÏÜåÏùå)";
        } else if (eventImpact > 10) {
            badge.textContent = "Impulsive (Ï∂©Í≤©Ïùå)";
            badge.className = "badge impulsive";
            comment.textContent = `Î∞∞Í≤Ω ÏÜåÏùåÎ≥¥Îã§ ${eventImpact.toFixed(0)}dB ÎÜíÏùÄ ÎèåÎ∞ú ÏÜåÏùåÏù¥ Í∞êÏßÄÎê©ÎãàÎã§. Î∂àÏæåÍ∞êÏù¥ ÌÅ¥ Ïàò ÏûàÏäµÎãàÎã§. (Ïòà: Î∞úÏÜåÎ¶¨, Î¨ºÍ±¥ ÎÇôÌïò)`;
        } else {
            badge.textContent = "Intermittent (Í∞ÑÌóêÏ†Å)";
            badge.className = "badge intermittent";
            comment.textContent = "Î∂àÍ∑úÏπôÌïú ÏÜåÏùå Î≥ÄÌôîÍ∞Ä Í∞êÏßÄÎê©ÎãàÎã§. (Ïòà: ÎåÄÌôî ÏÜåÎ¶¨, Í∞ÄÍπåÏö¥ TV ÏÜåÎ¶¨)";
        }
    }
}

function updateUI(current, bg) {
  meterBar.style.width = `${Math.min(100, Math.max(0, current))}%`;
  bgMarker.style.left = `${Math.min(100, Math.max(0, bg))}%`;
  currentVolSpan.textContent = Math.round(current);
  bgVolSpan.textContent = Math.round(bg);
  if (current > 75) meterBar.style.backgroundColor = '#f44336'; 
  else if (current > 50) meterBar.style.backgroundColor = '#ffeb3b'; 
  else meterBar.style.backgroundColor = '#4caf50'; 
}

function checkThreshold(current, bg) {
  // 0. Warm-up Period (Ignore first 3 seconds)
  if (Date.now() - audioInitTime < 3000) {
      statusText.textContent = "ÏÉÅÌÉú: ÎßàÏù¥ÌÅ¨ ÏïàÏ†ïÌôî Ï§ë...";
      backgroundLevel = current; // Instantly adapt background
      durationBar.style.width = '0%';
      noiseStartTime = 0;
      return;
  }

  if (isCalibrating) {
      statusText.textContent = "ÏÉÅÌÉú: ÎßàÏù¥ÌÅ¨ Î≥¥Ï†ï Ï§ë... (ÌèâÍ∞Ä ÏùºÏãúÏ§ëÏßÄ)";
      durationBar.style.width = '0%';
      return; 
  }
  if (Date.now() - lastEvalTime < GRACE_PERIOD_MS) {
      durationBar.style.width = '0%';
      return;
  }
  if (current < 30) { 
      noiseStartTime = 0;
      if (isRecording && !recordBtn.classList.contains('manual-lock')) { 
          cancelRecording();
          recordBtn.textContent = "üî¥ ÎÖπÏùå ÏãúÏûë";
          recordBtn.classList.remove('recording');
      }
      durationBar.style.width = '0%';
      statusText.textContent = "ÏÉÅÌÉú: Í∞êÏßÄ Ï§ë (Ï°∞Ïö©Ìï®)";
      return;
  }
  const triggerGap = 25 - (parseInt(thresholdSlider.value) / 100 * 20); 
  const triggerLevel = bg + triggerGap;
  if (current > triggerLevel) {
      if (noiseStartTime === 0) {
          noiseStartTime = Date.now();
          startRecording();
          recordBtn.textContent = "‚èπÔ∏è ÎÖπÏùå Ï§ëÏßÄ/ÏôÑÎ£å";
          recordBtn.classList.add('recording');
      }
      const duration = Date.now() - noiseStartTime;
      durationBar.style.width = `${Math.min(100, (duration / TRIGGER_DURATION_MS) * 100)}%`;
      statusText.textContent = `ÏÉÅÌÉú: ÏÜåÏùå Í∞êÏßÄ! Í∏∞Ï§Ä+${Math.round(triggerGap)}dB (${(duration/1000).toFixed(1)}s)`;
      if (duration > TRIGGER_DURATION_MS) triggerAlarm();
  } else {
      noiseStartTime = 0;
      if (isRecording && !recordBtn.classList.contains('manual-lock')) {
          cancelRecording();
          recordBtn.textContent = "üî¥ ÎÖπÏùå ÏãúÏûë";
          recordBtn.classList.remove('recording');
      }
      durationBar.style.width = '0%';
      statusText.textContent = "ÏÉÅÌÉú: Í∞êÏßÄ Ï§ë...";
  }
}

async function triggerAlarm() {
  if (isPausedForEval) return; 
  isPausedForEval = true; 
  noiseStartTime = 0;
  durationBar.style.width = '100%';
  statusText.textContent = "ÏÉÅÌÉú: ÏßÄÏÜçÏ†Å ÏÜåÏùå Î∞úÏÉù! ÌèâÍ∞Ä ÌïÑÏöî";
  
  // Stop and save recording
  recordedBlob = await stopRecording(true);
  
  // Reset Button UI
  recordBtn.textContent = "üî¥ ÎÖπÏùå ÏãúÏûë";
  recordBtn.classList.remove('recording');
  recordBtn.classList.remove('manual-lock');

  if (audioAlarmCheckbox.checked) playBeep();
  showEvaluationModal();
}

function showEvaluationModal() {
  modal.classList.remove('hidden');
  resetRatingUI();

  // Setup Audio Player if blob exists
  if (recordedBlob) {
      audioPreviewContainer.style.display = 'block';
      
      if (currentAudioUrl) {
          URL.revokeObjectURL(currentAudioUrl);
      }
      currentAudioUrl = URL.createObjectURL(recordedBlob);
      
      noisePlayer.src = currentAudioUrl;
      downloadLink.href = currentAudioUrl;
      const dateStr = new Date().toLocaleString().replace(/[:\/\s]/g, '-');
      downloadLink.download = `[ÎØ∏Î∂ÑÎ•ò]_${dateStr}.webm`;
  } else {
      audioPreviewContainer.style.display = 'none';
  }
}

function hideEvaluationModal() {
  modal.classList.add('hidden');
}

function resetRatingUI() {
  selectedRating = null;
  selectedValSpan.textContent = '-';
  submitEvalBtn.disabled = true;
  rateBtns.forEach(btn => btn.classList.remove('selected'));
  Object.values(chipGroups).forEach(group => {
      group.forEach(chip => chip.classList.remove('selected'));
  });
  surveyData = { activity: null, source: null };
}

function playBeep() {
    if (!audioContext) return;
    const osc = audioContext.createOscillator();
    const gain = audioContext.createGain();
    osc.connect(gain); gain.connect(audioContext.destination);
    osc.type = 'square'; osc.frequency.value = 880; 
    gain.gain.value = 0.1;
    osc.start(); osc.stop(audioContext.currentTime + 0.1);
}

// Button Events
calibBtn.addEventListener('click', async () => {
    if (!audioContext) await startAudio();
    calibModal.classList.remove('hidden');
});
cancelCalibBtn.addEventListener('click', () => {
    stopPinkNoise(); calibModal.classList.add('hidden');
});
playNoiseBtn.addEventListener('click', () => {
    if (isPlayingNoise) stopPinkNoise(); else playPinkNoise();
});
saveCalibBtn.addEventListener('click', () => {
    const realDb = parseFloat(realDbInput.value);
    const currentRaw = parseFloat(currentRawDbSpan.textContent);
    if (isNaN(realDb) || isNaN(currentRaw)) return;
    dbOffset = realDb - currentRaw;
    localStorage.setItem('dbOffset', dbOffset);
    alert(`Î≥¥Ï†ï ÏôÑÎ£å!`);
    stopPinkNoise(); calibModal.classList.add('hidden');
});

// Manual Record Button Logic
recordBtn.addEventListener('click', async () => {
    // Ensure mic is on
    if (!audioContext) {
        await startAudio();
    }
    
    if (!isRecording) {
        // Start Recording
        startRecording();
        recordBtn.textContent = "‚èπÔ∏è ÎÖπÏùå Ï§ëÏßÄ/ÏôÑÎ£å";
        recordBtn.classList.add('recording');
        recordBtn.classList.add('manual-lock'); // Mark as manual so threshold doesn't cancel it
        statusText.textContent = "ÏÉÅÌÉú: ÏàòÎèô ÎÖπÏùå Ï§ë...";
    } else {
        // Stop Recording
        recordBtn.textContent = "‚è≥ Ï≤òÎ¶¨ Ï§ë...";
        recordedBlob = await stopRecording(true);
        
        // Reset UI
        recordBtn.textContent = "üî¥ ÎÖπÏùå ÏãúÏûë";
        recordBtn.classList.remove('recording');
        recordBtn.classList.remove('manual-lock');
        statusText.textContent = "ÏÉÅÌÉú: Î™®ÎãàÌÑ∞ÎßÅ Ï§ë...";
        
        // Show Modal
        showEvaluationModal();
    }
});

rateBtns.forEach(btn => {
  btn.addEventListener('click', () => {
    rateBtns.forEach(b => b.classList.remove('selected'));
    btn.classList.add('selected');
    selectedRating = btn.dataset.val;
    selectedValSpan.textContent = selectedRating;
    checkSubmitReady();
  });
});

Object.entries(chipGroups).forEach(([type, chips]) => {
    chips.forEach(chip => {
        chip.addEventListener('click', () => {
            chips.forEach(c => c.classList.remove('selected'));
            chip.classList.add('selected');
            surveyData[type] = chip.dataset.val;
            
            // Update filename if source is selected
            if (type === 'source' && downloadLink.href) {
                const dateStr = new Date().toLocaleString().replace(/[:\/\s]/g, '-');
                // Use the Korean label text if available, or the value
                const labelText = chip.textContent.split('(')[0].trim(); // Get Korean part
                downloadLink.download = `[${labelText}]_${dateStr}.webm`;
            }
            
            checkSubmitReady();
        });
    });
});

function checkSubmitReady() {
    // Enable submit if rating is selected (source is optional but recommended for data)
    submitEvalBtn.disabled = (selectedRating === null);
}

submitEvalBtn.addEventListener('click', async () => {
  if (selectedRating === null) return;
  
  try {
    const profile = JSON.parse(localStorage.getItem('user_profile')) || {};
    const payload = {
      rating: parseInt(selectedRating, 10),
      noiseLevel: parseFloat(currentVolumeValue.toFixed(1)),
      backgroundLevel: Math.round(backgroundLevel),
      context: { activity: surveyData.activity || 'unknown', source: surveyData.source || 'unknown' },
      userProfile: profile,
      userAgent: navigator.userAgent, 
      timestamp: serverTimestamp()
      // Note: We are not uploading the audio blob to Firestore here because it requires Storage setup.
      // The user can download it locally.
    };
    await addDoc(collection(db, "noise_evaluations"), payload);
  } catch (err) { console.error(err); }
  hideEvaluationModal();
  lastEvalTime = Date.now();
  statusText.textContent = "ÏÉÅÌÉú: ÏïàÏ†ïÌôî Ï§ë...";
  isPausedForEval = false; 
  meterBar.style.width = '0%';
  durationBar.style.width = '0%';
  
  recordedBlob = null; // Clear memory
  if (currentAudioUrl) {
      URL.revokeObjectURL(currentAudioUrl);
      currentAudioUrl = null;
  }
  
  if (audioContext && audioContext.state === 'suspended') await audioContext.resume();
});

function drawSpectrogram() {
  requestAnimationFrame(drawSpectrogram);
  if (!isMonitoring || isPausedForEval) return;
  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);
  analyser.getByteFrequencyData(dataArray);
  tempCtx.drawImage(canvas, 0, 0, canvas.width, canvas.height);
  const width = canvas.width;
  const height = canvas.height;
  canvasCtx.drawImage(canvas, -1, 0);
  for (let i = 0; i < bufferLength; i++) {
    const value = dataArray[i];
    const percent = value / 255;
    const hue = (1 - percent) * 240; 
    canvasCtx.fillStyle = `hsl(${hue}, 100%, 50%)`;
    const y = height - Math.floor((i / bufferLength) * height);
    const h = Math.ceil(height / bufferLength); 
    canvasCtx.fillRect(width - 1, y - h, 1, h);
  }
}

function playPinkNoise() {
    if (!audioContext) return;
    const pinkBuffer = audioContext.createBuffer(1, audioContext.sampleRate * 2, audioContext.sampleRate);
    const data = pinkBuffer.getChannelData(0);
    let b0=0, b1=0, b2=0, b3=0, b4=0, b5=0, b6=0;
    for(let i=0; i<data.length; i++) {
        const white = Math.random() * 2 - 1;
        b0 = 0.99886 * b0 + white * 0.0555179; b1 = 0.99332 * b1 + white * 0.0750759;
        b2 = 0.96900 * b2 + white * 0.1538520; b3 = 0.86650 * b3 + white * 0.3104856;
        b4 = 0.55000 * b4 + white * 0.5329522; b5 = -0.7616 * b5 - white * 0.0168980;
        data[i] = (b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362) * 0.11;
        b6 = white * 0.115926;
    }
    noiseNode = audioContext.createBufferSource();
    noiseNode.buffer = pinkBuffer; noiseNode.loop = true;
    noiseNode.connect(audioContext.destination); noiseNode.start();
    isPlayingNoise = true; playNoiseBtn.textContent = "‚èπÔ∏è ÌïëÌÅ¨ ÎÖ∏Ïù¥Ï¶à Ï§ëÏßÄ";
}

function stopPinkNoise() {
    if (noiseNode) { noiseNode.stop(); noiseNode = null; }
    isPlayingNoise = false; playNoiseBtn.textContent = "üîä ÌïëÌÅ¨ ÎÖ∏Ïù¥Ï¶à Ïû¨ÏÉù";
}